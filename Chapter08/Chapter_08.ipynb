{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation Methods\n",
    "\n",
    "**Aim**: The aim of this notebook is understand the various performance evaluation methods that can be used to evaluate your model. \n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. Performance evaluation methods for classification algorithms\n",
    "2. Performance evaluation methods for regression algorithms \n",
    "3. Performance evaluation methods for unsupervised algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation methods for classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the K-Nearest Neighbors Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the fraud detection dataset \n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the K-NN Classifier \n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an logistic regression object\n",
    "\n",
    "logistic_regression = linear_model.LogisticRegression()\n",
    "\n",
    "#Fitting the model to the training and test sets\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Creating predictions on the test set \n",
    "\n",
    "prediction = knn_classifier.predict(X_test)\n",
    "\n",
    "#Creating the confusion matrix \n",
    "\n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the classification report \n",
    "\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalized Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized confusion matrix for the K-NN model\n",
    "\n",
    "prediction_labels = knn_classifier.predict(X_test)\n",
    "skplt.metrics.plot_confusion_matrix(y_test, prediction_labels, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized confusion matrix for the logistic regression model\n",
    "\n",
    "prediction_labels = logistic_regression.predict(X_test)\n",
    "skplt.metrics.plot_confusion_matrix(y_test, prediction_labels, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Area under the curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilities for each prediction output \n",
    "\n",
    "target_prob = knn_classifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "#Plotting the ROC curve \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, target_prob)\n",
    "\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the auc score \n",
    "\n",
    "roc_auc_score(y_test, target_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cumulative Gains Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative gains plot for the K-NN model\n",
    "\n",
    "target_prob = knn_classifier.predict_proba(X_test)\n",
    "skplt.metrics.plot_cumulative_gain(y_test, target_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative gains plot for the logistic regression model\n",
    "\n",
    "target_prob = logistic_regression.predict_proba(X_test)\n",
    "skplt.metrics.plot_cumulative_gain(y_test, target_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lift Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift curve for the K-NN model\n",
    "\n",
    "target_prob = knn_classifier.predict_proba(X_test)\n",
    "skplt.metrics.plot_lift_curve(y_test, target_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative gains plot for the logistic regression model\n",
    "\n",
    "target_prob = logistic_regression.predict_proba(X_test)\n",
    "skplt.metrics.plot_lift_curve(y_test, target_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KS-Statistic plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KS plot for the K-NN model\n",
    "\n",
    "target_proba = knn_classifier.predict_proba(X_test)\n",
    "skplt.metrics.plot_ks_statistic(y_test, target_proba)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KS plot for the logistic regression model\n",
    "\n",
    "target_proba = logistic_regression.predict_proba(X_test)\n",
    "skplt.metrics.plot_ks_statistic(y_test, target_proba)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calibration Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the probabilites that the positive class will be predicted\n",
    "\n",
    "knn_proba = knn_classifier.predict_proba(X_test)\n",
    "log_proba = logistic_regression.predict_proba(X_test)\n",
    "\n",
    "#Storing probabilities in a list\n",
    "\n",
    "probas = [knn_proba, log_proba]\n",
    "\n",
    "# Storing the model names in a list \n",
    "\n",
    "model_names = [\"k_nn\", \"Logistic Regression\"]\n",
    "\n",
    "#Creating the calibration plot\n",
    "\n",
    "skplt.metrics.plot_calibration_curve(y_test, probas, model_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning curve for the K-NN model\n",
    "\n",
    "skplt.estimators.plot_learning_curve(knn_classifier, features, target)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validated box plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of models\n",
    "\n",
    "models = [('k-NN', knn_classifier), ('LR', logistic_regression)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing empty lists in order to store the results\n",
    "cv_scores = []\n",
    "model_name_list = []\n",
    "\n",
    "for name, model in models:\n",
    "    \n",
    "    #5-fold cross validation\n",
    "    cv_5 = model_selection.KFold(n_splits= 5, random_state= 50)\n",
    "    # Evaluating the accuracy scores\n",
    "    cv_score = model_selection.cross_val_score(model, X_test, y_test, cv = cv_5, scoring= 'accuracy')\n",
    "    cv_scores.append(cv_score)\n",
    "    model_name_list.append(name)\n",
    "    \n",
    "# Plotting the cross-validated box plot \n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Boxplot of 5-fold cross validated scores for all the models')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(cv_scores)\n",
    "ax.set_xticklabels(model_name_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation methods for regression algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a linear regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a simple linear regression model\n",
    "\n",
    "#Reading in the dataset\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "#Define the feature and target arrays\n",
    "\n",
    "feature = df['oldbalanceOrg'].values\n",
    "target = df['amount'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing a linear regression model \n",
    "\n",
    "linear_reg = linear_model.LinearRegression()\n",
    "\n",
    "#Reshaping the array since we only have a single feature\n",
    "\n",
    "feature = feature.reshape(-1, 1)\n",
    "target = target.reshape(-1, 1)\n",
    "\n",
    "#Fitting the model on the data\n",
    "\n",
    "linear_reg.fit(feature, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear_reg.predict(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing the Mean Absoloute Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(target, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing the Mean Squared Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_squared_error(target, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing the Root Mean Squared Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(metrics.mean_squared_error(target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation methods for unsupervised algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building a K-Means model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the dataset\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "#Dropping the target feature & the index\n",
    "\n",
    "df = df.drop(['Unnamed: 0', 'isFraud'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing K-means with 2 clusters\n",
    "\n",
    "k_means = KMeans(n_clusters = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elbow plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.cluster.plot_elbow_curve(k_means, df, cluster_ranges=range(1, 20))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
